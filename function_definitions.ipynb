{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font', size=20)\n",
    "plt.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['xtick.labelsize'] = 15 \n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from .mpa files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spectrum(filename, start_line):    \n",
    "    '''\n",
    "    Get the spectrum of ADC1 in .mpa file. \n",
    "    Start line: contains the line [DATA0, 1024] or something similar in the .mpa file.\n",
    "    This may be determined using the function 'get_line_start'.\n",
    "    End line determined automatically from this line.\n",
    "    Returns list containing spectrum. In case of 2d spectrum some reshaping might be in order. \n",
    "    I suggest: np.reshape(list, (256,256)) :)\n",
    "    OR: np.reshape(list, (1024,4096))\n",
    "    '''\n",
    "    spec = []\n",
    "    with open(filename) as f:\n",
    "        # Loop over lines and keep track of line number\n",
    "        for i, line in enumerate(f):\n",
    "            if i == (start_line - 1):\n",
    "                try:                    \n",
    "                    # Unreadable line splits off part before ',' and part after ']'\n",
    "                    n_samples = (int(line.split(sep=',')[1].split(sep=']')[0]))\n",
    "                except:\n",
    "                    raise RuntimeError(\"Error: the line you indicated contains: %s\" % line)\n",
    "            if i >= start_line:\n",
    "                if i < start_line + n_samples:\n",
    "                    spec.append(int(line))\n",
    "    # Do some checking\n",
    "    print('Spectrum containing %d samples read, total %d counts' % (len(spec), sum(spec)))\n",
    "    if(sum(spec)==0):\n",
    "        print(\"Warning: empty spectrum\")\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_line_start(filename, string):\n",
    "    '''\n",
    "    Find the line in the text file that starts with the string supplied. (first occurrance)\n",
    "    Returns -1 if string not found.\n",
    "    The output of this may be used as imput to get_spectrum\n",
    "    '''\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        # Loop over lines and keep track of line number\n",
    "        for i, line in enumerate(f):\n",
    "            if len(line) < len(string):\n",
    "                continue\n",
    "            if line[:len(string)] == string:\n",
    "                return i + 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_full_line(filename, string):\n",
    "    '''\n",
    "    Find the line in the text file that starts with the string supplied. (first occurrance)\n",
    "    Returns the full line\n",
    "    '''\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        # Loop over lines and keep track of line number\n",
    "        for i, line in enumerate(f):\n",
    "            if len(line) < len(string):\n",
    "                continue\n",
    "            if line[:len(string)] == string:\n",
    "                # DEBUG\n",
    "                print(line)\n",
    "                return line\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mpa_entry(filename, string, endmarker='\\n', startmarker='='):\n",
    "    '''\n",
    "    Get the entry of a certain property in the .mpa file\n",
    "    String: start of the line to be extracted\n",
    "    '''\n",
    "    line = find_full_line(filename, string) # Get the full line\n",
    "    line = line.split(sep=startmarker)[1] # Split off everything before '='\n",
    "    line = line.split(sep=endmarker)[0] # Split off everything before endmarker\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mpa_data(fn):\n",
    "    '''\n",
    "    Get the following data from the .mpa file:\n",
    "      - \n",
    "      - \n",
    "    WARNING: if a line occurs multiple times in the file, we will take the FIRST one!\n",
    "    '''\n",
    "    # Initialize dictionary that is to hold all data\n",
    "    d = {}\n",
    "    \n",
    "    \n",
    "    d['runtime'] = float(get_mpa_entry(fn, 'scrtime'))\n",
    "    d['gm_counts'] = int(get_mpa_entry(fn, 'sc#05', ';'))\n",
    "    d['lc_counts'] = int(get_mpa_entry(fn, 'sc#07', ';'))\n",
    "    d['livetime'] = float(get_mpa_entry(fn, 'livetime'))\n",
    "    d['start_time_seconds'] = float(get_mpa_entry(fn, 'scrtstart', endmarker=';'))\n",
    "    d['start_datetime'] = convert_mpa_time(\n",
    "                            ' ' + get_mpa_entry(fn, 'scrtstart', startmarker=';')) # ' ' for backward compatibility\n",
    "    d['end_datetime'] = d['start_datetime'] + datetime.timedelta(seconds = d['runtime'])\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from .msa files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_msa_data(count_file, verbose = True):\n",
    "    counts = []\n",
    "    with open(count_file) as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            # Don't read the header\n",
    "            if i==0:\n",
    "                i = i+1\n",
    "                continue\n",
    "            # Split on spaces\n",
    "            split_line = np.array(line.split(sep=' '))\n",
    "            # Remove all the extra entries caused by spaces\n",
    "            split_line = [x for x in split_line if x != '']\n",
    "\n",
    "            dt = np.dtype([\n",
    "                    ('date',np.str_,20),\n",
    "                    ('time',np.str_,20),\n",
    "                    ('interval', np.float),\n",
    "                    ('gm_counts', np.int),\n",
    "                    ('lc_counts', np.int),\n",
    "                    ('end', datetime.datetime),\n",
    "                    ('start', datetime.datetime),\n",
    "                  ])\n",
    "            d = np.zeros(1,dtype=dt)\n",
    "            d['date']     = str(split_line[1])\n",
    "            d['time']     = str(split_line[2])\n",
    "            d['interval'] = 0.01*float(split_line[3])\n",
    "            d['end']      = convert_count_time(d['date'][0],d['time'][0])\n",
    "            d['start']    = d['end'][0] - datetime.timedelta(seconds = d['interval'][0])\n",
    "            d['gm_counts']= int(split_line[7])\n",
    "            d['lc_counts']= int(split_line[9])\n",
    "            counts.append(d)\n",
    "\n",
    "            i = i+1\n",
    "    counts = np.concatenate(counts)\n",
    "\n",
    "    if verbose: print(\"Read %d datasets\" % (len(counts)))\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting fucking timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_mpa_time(s):\n",
    "    '''\n",
    "    Take a string in the format of mpa file and convert it to something sensible.\n",
    "    Example string: '; 05/30/2016 16:46:00\\n'\n",
    "    '''\n",
    "    month = int(s[2:4])\n",
    "    day = int(s[5:7])\n",
    "    year = int(s[8:12])\n",
    "    hour = int(s[13:15])\n",
    "    minute = int(s[16:18])\n",
    "    second = int(s[19:21])\n",
    "    return datetime.datetime(year,month,day,hour,minute,second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sc_time(s):\n",
    "    '''\n",
    "    Take a string in the format of SC program and convert it to something sensible.\n",
    "    Example string: \"b'25.05.2016 13:30:56\"\n",
    "    '''\n",
    "    # Cut off b' part\n",
    "    s = s[2:]\n",
    "    day = int(s[0:2])\n",
    "    month = int(s[3:5])\n",
    "    year = int(s[6:10])\n",
    "    hour = int(s[11:13])\n",
    "    minute = int(s[14:16])\n",
    "    second = int(s[17:19])\n",
    "    return datetime.datetime(year,month,day,hour,minute,second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_count_time(date,time):\n",
    "    '''\n",
    "    Take string in format of counter and convert it.\n",
    "    '25-MAY-2016', '15:44:54'\n",
    "    '''\n",
    "    day = int(date[0:2])\n",
    "    month_str = (date[3:6])\n",
    "    if month_str == 'MAY':\n",
    "        month = 5\n",
    "    else:\n",
    "        raise ValueError(\"What? How dare you operate outside of May?!\")\n",
    "    year = int(date[-4:])\n",
    "    hour = int(time[0:2])\n",
    "    minute = int(time[3:5])\n",
    "    second = int(time[6:8])\n",
    "    return datetime.datetime(year,month,day,hour,minute,second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D histogram manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rebin_x(arr2d):\n",
    "    '''\n",
    "    Rebin 2d histogram by a factor of 2 in the x-direction\n",
    "    '''\n",
    "    return np.array(\n",
    "        [arr2d[i] + arr2d[i +1] for i in np.arange(0,len(arr2d),2)]\n",
    "    )\n",
    "\n",
    "def rebin_y(arr2d):\n",
    "    '''\n",
    "    Rebin 2d histogram by a factor of 2 in the y-direction\n",
    "    '''\n",
    "    return np.array(\n",
    "    [ [x[i] + x[i + 1] for i in np.arange(0,len(x),2)]  for x in arr2d       \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_hist2d(arr2d, f):\n",
    "    '''\n",
    "    Set bin content to 0 whenever f(x,y) yields False\n",
    "    '''\n",
    "    return np.array([\n",
    "            \n",
    "            [arr2d[y][x] if f(x,y) else 0 for x in range(len(arr2d[y]))]\n",
    "            for y in range(len(arr2d))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_percentile_pos(dist, percent):\n",
    "    '''\n",
    "    Get the position in the list containing histogram of the percentile\n",
    "    No, np.percentile does NOT work, since we're dealing with the histogram rather than the values themselves!\n",
    "    If you care about +-1 accuracy, better check what makes sense because I didn't.\n",
    "    This takes lower bound.\n",
    "    '''\n",
    "    tot = sum(dist)\n",
    "    count = 0\n",
    "    for i, x in enumerate(dist):\n",
    "        if count >= tot*percent/100.:\n",
    "            return i\n",
    "        count += x\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slow control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sc_data(filename):\n",
    "    # Load SC data\n",
    "    dt = np.dtype([('date-time',np.str_,21),\n",
    "                   ('v', np.float64),\n",
    "                   ('v_set', np.float64),\n",
    "                   ('i', np.float64),\n",
    "                   ('i_set', np.float64),\n",
    "                   ('temp_basic', np.float64),\n",
    "                   ('temp_coset', np.float64),\n",
    "                   ('temp', np.float64),\n",
    "                  ])\n",
    "    sc_data = np.loadtxt(filename, dtype=dt, delimiter = ',', skiprows=1, usecols=(0,1,2,4,5,8,9,10))\n",
    "    \n",
    "    # Convert the STRING date-time to a datetime.datetime timestamp\n",
    "    t = np.array([convert_sc_time(datetime) for datetime in sc_data['date-time'] ])\n",
    "    \n",
    "    return t, sc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_correction_factor(t, sc_data, start_datetime, end_datetime, verbose=True, plot=False):\n",
    "    '''\n",
    "    Get the correction factor based on voltage and current readings.\n",
    "    filename: SC file name\n",
    "    '''\n",
    "    \n",
    "    # Get a mask within time range\n",
    "    time_mask = (t > start_datetime) & (t < end_datetime)\n",
    "    dead = (t > start_datetime) & (t < end_datetime) & (sc_data['i'] < 0.4)\n",
    "    mask = (t > start_datetime) & (t < end_datetime) & (sc_data['i'] >= 0.4)\n",
    "    \n",
    "#     v_power = 3.5\n",
    "#     i_power = 1.\n",
    "    v_power = 3.33\n",
    "    i_power = 1.00\n",
    "    print('NOTE: we are now using: v = 3.33, i = 1.00')\n",
    "    \n",
    "    v_eff = (np.average(sc_data[mask]['v']**v_power))**(1/v_power)\n",
    "    i_eff = (np.average(sc_data[mask]['i']**i_power))**(1/i_power)\n",
    "    t_dead = len(t[dead])\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"v_eff: %f\" % v_eff)\n",
    "        print(\"v_avg: %f\" % np.average(sc_data[mask]['v']))\n",
    "        print(\"v_std: %f\" % np.std(sc_data[mask]['v']))\n",
    "        print(\"\")\n",
    "        print(\"i_eff: %f\" % i_eff)\n",
    "        print(\"i_avg: %f\" % np.average(sc_data[mask]['i']))\n",
    "        print(\"i_std: %f\" % np.std(sc_data[mask]['i']))    \n",
    "        print(\"\")\n",
    "        print(\"deadtime: %d\" % t_dead)\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(t[time_mask],sc_data[time_mask]['v'], label='voltage', color='blue')\n",
    "        if len(t[dead]) > 0:\n",
    "            plt.scatter(t[dead],sc_data[dead]['v'], label='voltage', color='red')\n",
    "\n",
    "        plt.axhline(v_eff,ls='--', lw=1.5, color='blue', label = 'v_eff')\n",
    "        plt.ylabel('Voltage (kV)')\n",
    "        plt.ylim(0,60)\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.twinx()\n",
    "        plt.plot(t[time_mask],sc_data[time_mask]['i'], label='current', color='green')\n",
    "        plt.axhline(i_eff,ls='--', lw=1.5, color='green', label = 'i_eff')\n",
    "        if len(t[dead]) > 0:\n",
    "            plt.scatter(t[dead],sc_data[dead]['i'], label='deadtime', color='red')\n",
    "        plt.ylabel('Current (mA)')\n",
    "        plt.ylim(0,2.5)\n",
    "        \n",
    "        plt.legend(loc='lower right')\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        plt.show()\n",
    "        \n",
    "    return v_eff, i_eff, t_dead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .flu data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_flu(filename):\n",
    "    col0 = []\n",
    "    col1 = []\n",
    "    col2 = []\n",
    "    with open(filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i<3:\n",
    "                continue\n",
    "            split_line = line.split(sep=' ')\n",
    "            split_line = np.array([float(x) for x in split_line if ((x != '') and (x != '\\n'))])\n",
    "            col0.append(split_line[0])\n",
    "            col1.append(split_line[1])\n",
    "            col2.append(split_line[2])\n",
    "    assert np.all(col1 == col2)\n",
    "    return np.array(col0), np.array(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_gru(filename):\n",
    "    col0 = []\n",
    "    col1 = []\n",
    "    col2 = []\n",
    "    with open(filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i<3:\n",
    "                continue\n",
    "            split_line = line.split(sep=' ')\n",
    "            split_line = np.array([float(x) for x in split_line if ((x != '') and (x != '\\n'))])\n",
    "            col0.append(split_line[0])\n",
    "            col1.append(split_line[1])\n",
    "            col2.append(split_line[2])\n",
    "    assert np.all(col1 == col2)\n",
    "    return np.array(col0), np.array(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_phs_data(filename):\n",
    "    return read_flu(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gamma calibration functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fwhm_pos(d, edge = 'right'):\n",
    "    '''\n",
    "    Get index of FWHM, right edge\n",
    "    '''\n",
    "    if edge != 'right':\n",
    "        raise NotImplementedError('Just right edge for now!')\n",
    "     \n",
    "    max_val = max(d)\n",
    "    max_index = d.index(max_val)\n",
    "    for i in range(max_index, len(d) - max_index):\n",
    "        if d[i] < max_val*0.5:\n",
    "            return i\n",
    "    return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compton_energy(e):\n",
    "    '''\n",
    "    \n",
    "    https://en.wikipedia.org/wiki/Compton_edge (but I also checked other places, don't worry)\n",
    "    '''\n",
    "    return e*(1-1/(1+(2*e/511.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_1(x, a0, a1):\n",
    "    return a0 + a1*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_to_array(array,column,name):\n",
    "    '''\n",
    "    Append a column to a numpy array.\n",
    "    DISCLAIMER this will probably be VERY slow for large arrays, because the code is ugly... \n",
    "    If you know a better way, PLEASE tell me!\n",
    "    '''\n",
    "    # In case of list convert to array\n",
    "    column = np.array(column)\n",
    "    \n",
    "    # This gives you a // list // of dtypes\n",
    "    dt_old = array.dtype.base.descr\n",
    "    # Detect current type and store it\n",
    "    dtype = tuple((name,column.dtype))\n",
    "    \n",
    "    # Now, we construct the dtype list for the NEW array\n",
    "    # Lord knows why but we have to do it THIS way...\n",
    "    dt_new = []\n",
    "    for tup in dt_old:\n",
    "        dt_new.append(tup)\n",
    "    dt_new.append(dtype)\n",
    "    array_new = np.zeros(len(array),dtype = dt_new)\n",
    "    \n",
    "    # After that we set the fields. \n",
    "    # Again... One by one...\n",
    "    # TODO can this be faster?\n",
    "    # Set the old fields\n",
    "    for field_name in array.dtype.names:\n",
    "        array_new[field_name] = array[field_name]\n",
    "    # Set the new field\n",
    "    array_new[dtype[0]] = column\n",
    "    \n",
    "    # Done!\n",
    "    return array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rebin(arr, factor=2, mode='avg'):\n",
    "    '''\n",
    "    Rebin an array. Take integer factor. Modes available:\n",
    "      - avg: average. Default.\n",
    "      - sum: Sum.\n",
    "      - quad: adding all in quadrature. Mostly for errors.\n",
    "      - quad_avg: adding all in quadrature, then taking average. For errors on averages.\n",
    "    '''\n",
    "    if mode == 'avg':\n",
    "        rebin = np.array([1/factor*sum(arr[i:i + factor]) for i in np.arange(0, len(arr), factor)])\n",
    "    elif mode == 'sum':\n",
    "        rebin = np.array([sum(arr[i:i + factor]) for i in np.arange(0, len(arr), factor)])\n",
    "    elif mode == 'quad':\n",
    "        rebin = np.array([np.sqrt(sum(arr[i:i + factor]**2))\n",
    "                          for i in np.arange(0, len(arr), factor)])\n",
    "    elif mode == 'quad_avg':\n",
    "        rebin = np.array([1/factor*np.sqrt(sum(arr[i:i + factor]**2))\n",
    "                          for i in np.arange(0, len(arr), factor)])\n",
    "    else:\n",
    "        raise SyntaxError('Did not get the rebinning mode, you specified: %s' % mode)\n",
    "    \n",
    "    return rebin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "def draw_box(x, y, **kwargs):\n",
    "    \"\"\"Draw rectangle, given x-y boundary tuples\"\"\"\n",
    "    # Arcane syntax of the week: matplotlib's Rectangle...\n",
    "    plt.gca().add_patch(mpl.patches.Rectangle(\n",
    "        (x[0], y[0]), x[1] - x[0], y[1] - y[0],  **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_x():\n",
    "    '''\n",
    "    I keep forgetting this command\n",
    "    '''\n",
    "    \n",
    "    plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    '''\n",
    "    Normalized Gaussian function\n",
    "    '''\n",
    "    return 1./(np.sqrt(2.*np.pi)*sig)*np.exp(-np.power((x - mu)/sig, 2.)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_element_pos(arr, number):\n",
    "    diff = list(np.abs(arr - number))\n",
    "    return diff.index(min(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_remove_lowest_tick():\n",
    "    '''\n",
    "    Alias of: plt.gca().yaxis.set_major_locator(mpl.ticker.MaxNLocator(prune='lower'))\n",
    "    '''\n",
    "    plt.gca().yaxis.set_major_locator(mpl.ticker.MaxNLocator(prune='lower'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
